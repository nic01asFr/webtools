# üìö WebTools API - Guide des Cas d'Usage et Patterns

> **Guide pratique pour utilisateurs individuels et d√©veloppeurs d'agents IA**

Ce guide pr√©sente les patterns d'utilisation des 13 endpoints WebTools, avec des exemples concrets et des cas d'usage m√©tier. Que vous utilisiez l'API directement ou que vous d√©veloppiez un agent IA qui orchestrera ces endpoints, vous trouverez ici les bonnes pratiques et patterns optimaux.

---

## üìñ Table des Mati√®res

1. [Patterns Simples (1 endpoint)](#-patterns-simples-1-endpoint)
2. [Patterns de Cha√Ænage (2-3 endpoints)](#-patterns-de-cha√Ænage-2-3-endpoints)
3. [Patterns Avanc√©s (Deep Research)](#-patterns-avanc√©s-deep-research)
4. [Cas d'Usage M√©tier](#-cas-dusage-m√©tier)
5. [Guide pour D√©veloppeurs d'Agents](#-guide-pour-d√©veloppeurs-dagents)

---

## üéØ Patterns Simples (1 endpoint)

### 1Ô∏è‚É£ `/api/v1/extract` - Extraction de Contenu

#### Pattern 1.1: Extraction Basique
**Cas d'usage**: Extraire le contenu texte propre d'une page web

```json
POST /api/v1/extract
{
  "url": "https://example.com/article",
  "options": {
    "clean_html": true,
    "extract_images": false,
    "extract_links": false,
    "timeout": 30
  }
}
```

**R√©sultat**: Texte nettoy√© sans navigation, publicit√©s, scripts

---

#### Pattern 1.2: Extraction avec Liens
**Cas d'usage**: Extraire le contenu + tous les liens internes (pour exploration)

```json
POST /api/v1/extract
{
  "url": "https://docs.python.org/3/tutorial",
  "options": {
    "clean_html": true,
    "extract_images": false,
    "extract_links": true,
    "timeout": 30
  }
}
```

**R√©sultat**: Contenu + liste de liens `[{url, text, type}]`

**Utilisation**:
- Mapper une documentation compl√®te
- D√©couvrir toutes les sous-pages d'un site
- Base pour un crawler cibl√©

---

#### Pattern 1.3: Extraction avec Images
**Cas d'usage**: R√©cup√©rer contenu + URLs d'images (graphiques, diagrammes)

```json
POST /api/v1/extract
{
  "url": "https://insee.fr/statistiques-2024",
  "options": {
    "clean_html": true,
    "extract_images": true,
    "extract_links": false,
    "timeout": 45
  }
}
```

**R√©sultat**: Contenu + URLs images pour analyse ult√©rieure avec `/vision`

---

### 2Ô∏è‚É£ `/api/v1/vision` - Analyse d'Images

#### Pattern 2.1: OCR (Extraction de Texte)
**Cas d'usage**: Extraire texte depuis une image (document scann√©, screenshot)

```json
POST /api/v1/vision
{
  "image_url": "https://example.com/document-scan.png",
  "prompt": "Extraire tout le texte de cette image",
  "temperature": 0.0,
  "max_tokens": 1000
}
```

**Utilisation**:
- Num√©riser documents papier
- Extraire texte de screenshots
- R√©cup√©rer URLs visibles dans captures d'√©cran

---

#### Pattern 2.2: Analyse de Graphiques/Tableaux
**Cas d'usage**: Extraire les donn√©es num√©riques d'un graphique

```json
POST /api/v1/vision
{
  "image_url": "https://example.com/sales-chart.png",
  "prompt": "Extraire toutes les valeurs num√©riques et labels de ce graphique. Formater en JSON.",
  "system_prompt": "Tu es un expert en analyse de donn√©es visuelles. Retourne uniquement un JSON structur√©.",
  "temperature": 0.1,
  "max_tokens": 800
}
```

**R√©sultat**: Donn√©es structur√©es exploitables (JSON)

---

#### Pattern 2.3: Description/Classification
**Cas d'usage**: Identifier le contenu d'une image (logos, UI, photos)

```json
POST /api/v1/vision
{
  "image_url": "https://example.com/interface.png",
  "prompt": "D√©crire cette interface utilisateur. Quels sont les √©l√©ments principaux et leur fonction?",
  "temperature": 0.2,
  "max_tokens": 500
}
```

**Utilisation**:
- Audit UX/UI
- Classification automatique d'images
- D√©tection d'√©l√©ments sp√©cifiques

---

### 3Ô∏è‚É£ `/api/v1/search` - Recherche Web Intelligente

#### Pattern 3.1: Recherche Basique
**Cas d'usage**: Recherche simple avec SearXNG

```json
POST /api/v1/search
{
  "query": "FastAPI tutorial",
  "categories": ["general"],
  "language": "fr",
  "max_results": 10
}
```

---

#### Pattern 3.2: Recherche avec Google Dorking
**Cas d'usage**: Recherches sp√©cialis√©es (fichiers, sites sp√©cifiques, types de contenu)

```json
POST /api/v1/search
{
  "query": "r√©glementation signalisation routi√®re",
  "dorking": true,
  "categories": ["general", "files"],
  "language": "fr",
  "max_results": 15
}
```

**Comportement**: Active automatiquement les dorks appropri√©s
- `filetype:pdf` pour documents
- `site:gouv.fr` pour sites officiels
- `intitle:` pour recherches pr√©cises

---

#### Pattern 3.3: Ciblage de Site
**Cas d'usage**: Rechercher uniquement sur un site/domaine sp√©cifique

```json
POST /api/v1/search
{
  "query": "API endpoints authentication",
  "target_url": "https://docs.fastapi.com",
  "scope": "site",
  "max_results": 10
}
```

**Options de scope**:
- `"site"`: Tout le domaine (ex: `site:docs.fastapi.com`)
- `"domain"`: Domaine racine (ex: `site:fastapi.com`)
- `"page"`: Page exacte

---

#### Pattern 3.4: Enrichissement LLM + Scoring
**Cas d'usage**: Am√©liorer la requ√™te et scorer la pertinence des r√©sultats

```json
POST /api/v1/search
{
  "query": "comment d√©ployer une api",
  "llm_enrichment": true,
  "relevance_scoring": true,
  "language": "fr",
  "max_results": 10
}
```

**Comportement**:
- `llm_enrichment`: Enrichit la requ√™te (synonymes, contexte)
  - "comment d√©ployer une api" ‚Üí "API deployment production Docker Kubernetes server hosting"
- `relevance_scoring`: Score chaque r√©sultat (0-1) selon pertinence avec la requ√™te originale

---

### 4Ô∏è‚É£ `/api/v1/research/quick` - R√©ponse Rapide Document√©e

#### Pattern 4.1: Recherche Ouverte (par d√©faut)
**Cas d'usage**: Question simple, recherche web automatique

```json
POST /api/v1/research/quick
{
  "query": "Quelle est la capitale du Japon?",
  "max_sources": 5,
  "include_citations": true,
  "timeout": 60
}
```

**Comportement**:
- Recherche web via SearXNG
- Extrait contenu de 5 sources
- G√©n√®re r√©ponse avec citations `[1][2]`

---

#### Pattern 4.2: Sources Prioritaires (`priority`)
**Cas d'usage**: Privil√©gier certaines sources mais accepter compl√©ments web si insuffisant

```json
POST /api/v1/research/quick
{
  "query": "Statistiques d√©mographiques France 2024",
  "sources": {
    "urls": [
      "https://www.insee.fr",
      "https://data.gouv.fr/datasets/population"
    ],
    "strategy": "priority"
  },
  "max_sources": 8,
  "timeout": 90
}
```

**Comportement**:
1. Essaie d'extraire les URLs fournies en premier
2. Si insuffisant (< 8 sources) ‚Üí Recherche web compl√©mentaire
3. G√©n√®re r√©ponse en privil√©giant les sources fournies

**Utilisation**:
- Privil√©gier documentation officielle tout en acceptant tutoriels communautaires
- Partir de sources connues et compl√©ter si n√©cessaire

---

#### Pattern 4.3: Sources Exclusives (`exclusive`)
**Cas d'usage**: UNIQUEMENT les sources fournies, pas de recherche web

```json
POST /api/v1/research/quick
{
  "query": "Obligations de signalisation temporaire sur chantiers",
  "sources": {
    "urls": [
      "https://legifrance.gouv.fr/codes/id/LEGISCTA000006177118",
      "https://www.securite-routiere.gouv.fr/reglementation-liee-la-route/signalisation-routiere",
      "https://demarches-securite-routes.cerema.fr"
    ],
    "strategy": "exclusive"
  },
  "max_sources": 10,
  "timeout": 120
}
```

**Comportement**:
- ‚ùå **Pas de recherche web** (SearXNG d√©sactiv√©)
- ‚úÖ Uniquement extraction des URLs fournies
- Si √©chec extraction ‚Üí Erreur "No results from provided URLs (exclusive strategy)"

**Utilisation**:
- R√©ponses 100% fiables (r√©glementation, sources officielles)
- Contexte l√©gal/m√©dical o√π sources non v√©rifi√©es sont inacceptables
- Audit de conformit√©

---

#### Pattern 4.4: Compl√©ments Web (`complement`)
**Cas d'usage**: Recherche web normale + ajout d'URLs sp√©cifiques

```json
POST /api/v1/research/quick
{
  "query": "Tutoriel avanc√© FastAPI webhooks",
  "sources": {
    "urls": [
      "https://fastapi.tiangolo.com/advanced/events",
      "https://fastapi.tiangolo.com/advanced/websockets"
    ],
    "strategy": "complement"
  },
  "max_sources": 10,
  "timeout": 90
}
```

**Comportement**:
1. Recherche web normale via SearXNG
2. Ajoute les URLs fournies aux r√©sultats
3. Extrait tout et g√©n√®re r√©ponse compl√®te

**Utilisation**:
- Ajouter documentation officielle aux r√©sultats web
- Garantir pr√©sence de sources cl√©s dans la r√©ponse

---

### 5Ô∏è‚É£ `/api/v1/research/deep` - Rapport de Recherche Approfondi

> **Note**: Deep Research utilise l'Intelligent Orchestrator avec architecture 4-phase (Exploration ‚Üí Planning ‚Üí Construction ‚Üí Coh√©rence). Voir `DEEP_RESEARCH_ARCHITECTURE.md` pour d√©tails techniques.

#### Pattern 5.1: D√©couverte Totale (Audit Syst√©mique)
**Cas d'usage**: Recherche exploratoire compl√®te, aucune source impos√©e

```json
POST /api/v1/research/deep
{
  "topic": "Audit syst√©mique de la r√©glementation de signalisation routi√®re fran√ßaise",
  "objectives": [
    "Identifier les top 50 failles critiques",
    "D√©tecter les patterns r√©currents (ex: terme 'exceptionnel' mal d√©fini)",
    "Analyser les failles syst√©miques",
    "Proposer des recommandations de r√©forme"
  ],
  "sources": {
    "required": [],
    "suggested": [],
    "exclusions": [],
    "domains_whitelist": []
  },
  "context": {
    "language": "fr",
    "min_sources": 30,
    "include_reports": true,
    "include_academic": true,
    "include_data": true
  },
  "max_steps": 20,
  "timeout": 600
}
```

**Comportement**:
- Phase 1: Exploration via SearXNG (d√©couverte automatique)
- Phase 2: Construction section par section avec recherches cibl√©es
- Phase 3: Coh√©rence globale et croisement inter-sections
- Phase 4: Rapport final avec bibliographie compl√®te

**R√©sultat**: Rapport structur√© avec 5-10 sections, 30+ sources, bibliographie, m√©tadonn√©es d'ex√©cution

**Utilisation**:
- √âtudes de march√© compl√®tes
- Audits r√©glementaires
- √âtats de l'art techniques
- Dossiers de recherche acad√©miques

---

#### Pattern 5.2: Sources Officielles UNIQUEMENT (`required`)
**Cas d'usage**: Rapport bas√© exclusivement sur sources de confiance

```json
POST /api/v1/research/deep
{
  "topic": "√âvolution du droit du travail fran√ßais 2024",
  "objectives": [
    "Recenser les changements l√©gislatifs",
    "Analyser l'impact sur les entreprises",
    "Identifier les nouvelles obligations employeurs"
  ],
  "sources": {
    "required": [
      "https://legifrance.gouv.fr",
      "https://travail-emploi.gouv.fr",
      "https://www.vie-publique.fr"
    ],
    "suggested": [],
    "exclusions": [],
    "domains_whitelist": []
  },
  "context": {
    "language": "fr",
    "min_sources": 15
  },
  "max_steps": 15,
  "timeout": 600
}
```

**Comportement**:
- ‚ö†Ô∏è **BLOQUANT**: Si extraction √©choue sur une URL `required` ‚Üí Erreur fatale
- Recherches cibl√©es uniquement sur ces domaines
- Garantit fiabilit√© 100%

**Utilisation**:
- Documents l√©gaux/r√©glementaires
- Rapports de conformit√©
- Audits officiels
- Contextes n√©cessitant sources v√©rifi√©es

---

#### Pattern 5.3: Recherche Guid√©e (`suggested`)
**Cas d'usage**: Partir de sources connues + exploration compl√©mentaire

```json
POST /api/v1/research/deep
{
  "topic": "√âtat de l'art IA g√©n√©rative - Mod√®les de langage 2024",
  "objectives": [
    "Recenser les mod√®les LLM r√©cents",
    "Comparer performances et capacit√©s",
    "Analyser les tendances et innovations"
  ],
  "sources": {
    "required": [],
    "suggested": [
      "https://arxiv.org",
      "https://huggingface.co/papers",
      "https://openai.com/research",
      "https://www.anthropic.com/research"
    ],
    "exclusions": ["blog.*", "medium.com"],
    "domains_whitelist": []
  },
  "context": {
    "language": "en",
    "min_sources": 25,
    "include_academic": true
  },
  "max_steps": 20,
  "timeout": 600
}
```

**Comportement**:
1. Commence par extraire les URLs `suggested` (prioritaires)
2. Si insuffisant (< 25 sources) ‚Üí D√©couverte compl√©mentaire via SearXNG
3. Filtre les domaines dans `exclusions`

**Utilisation**:
- Recherches acad√©miques avec sources de r√©f√©rence
- Documentation technique avec sites connus
- Veille technologique guid√©e

---

#### Pattern 5.4: Whitelist Domaines
**Cas d'usage**: Limiter la recherche √† des domaines de confiance sp√©cifiques

```json
POST /api/v1/research/deep
{
  "topic": "Donn√©es publiques fran√ßaises disponibles - Inventaire complet",
  "objectives": [
    "Recenser toutes les APIs gouvernementales",
    "Lister les datasets ouverts",
    "Documenter les conditions d'acc√®s"
  ],
  "sources": {
    "required": [],
    "suggested": [],
    "exclusions": [],
    "domains_whitelist": [
      "gouv.fr",
      "data.gouv.fr",
      "insee.fr",
      "legifrance.gouv.fr",
      "service-public.fr"
    ]
  },
  "context": {
    "language": "fr",
    "min_sources": 20,
    "include_data": true
  },
  "max_steps": 15,
  "timeout": 600
}
```

**Comportement**:
- D√©couverte via SearXNG avec: `site:gouv.fr OR site:data.gouv.fr OR site:insee.fr...`
- Filtre **TOUS** r√©sultats hors whitelist
- Garantit sources gouvernementales/officielles uniquement

**Utilisation**:
- Veille r√©glementaire gouvernementale
- Inventaire de ressources officielles
- Recherches n√©cessitant sources publiques uniquement

---

#### Pattern 5.5: Blacklist Domaines (`exclusions`)
**Cas d'usage**: √âviter sources non fiables (forums, blogs, r√©seaux sociaux)

```json
POST /api/v1/research/deep
{
  "topic": "√âtudes scientifiques - Efficacit√© vaccins COVID-19",
  "objectives": [
    "Recenser √©tudes peer-reviewed",
    "Analyser les r√©sultats cliniques",
    "Synth√©tiser le consensus scientifique"
  ],
  "sources": {
    "required": [],
    "suggested": ["https://pubmed.ncbi.nlm.nih.gov", "https://www.thelancet.com"],
    "exclusions": [
      "forum.*",
      "blog.*",
      "facebook.com",
      "twitter.com",
      "*reddit.com",
      "quora.com",
      "medium.com"
    ],
    "domains_whitelist": []
  },
  "context": {
    "language": "en",
    "min_sources": 30,
    "include_academic": true
  },
  "max_steps": 20,
  "timeout": 600
}
```

**Comportement**:
- D√©couvre sources via SearXNG
- Filtre URLs matchant les patterns `exclusions` (wildcards `*` support√©s)
- Privil√©gie sources acad√©miques/scientifiques

**Utilisation**:
- Recherches scientifiques (√©viter opinions)
- Analyses factuelles (√©viter biais)
- Documentation technique (√©viter blogs amateurs)

---

## üîó Patterns de Cha√Ænage (2-3 endpoints)

> **Pour d√©veloppeurs d'agents**: Ces patterns montrent comment orchestrer plusieurs endpoints pour cr√©er des workflows complexes.

### Pattern A: Search ‚Üí Extract ‚Üí Vision
**Cas d'usage**: Trouver pages avec graphiques ‚Üí Extraire images ‚Üí Analyser donn√©es visuelles

```json
// === √âTAPE 1: Rechercher pages avec graphiques ===
POST /api/v1/search
{
  "query": "statistiques d√©mographiques France graphiques INSEE",
  "dorking": true,
  "categories": ["general", "images"],
  "max_results": 5
}

// R√©sultat:
// {
//   "results": [
//     {"url": "https://insee.fr/stats-2024", "title": "Statistiques 2024"},
//     {"url": "https://data.gouv.fr/demo-france", "title": "D√©mographie"}
//   ]
// }

// === √âTAPE 2: Extraire contenu + images de chaque page ===
POST /api/v1/extract
{
  "url": "https://insee.fr/stats-2024",
  "options": {
    "extract_images": true,
    "extract_links": false
  }
}

// R√©sultat:
// {
//   "images": [
//     "https://insee.fr/graphs/population-2024.png",
//     "https://insee.fr/charts/age-pyramid.png"
//   ]
// }

// === √âTAPE 3: Analyser chaque graphique ===
for each image_url in images:
  POST /api/v1/vision
  {
    "image_url": image_url,
    "prompt": "Extraire toutes les donn√©es num√©riques de ce graphique. Retourner en JSON avec format: {labels: [], values: []}",
    "system_prompt": "Tu es un expert en extraction de donn√©es visuelles. Retourne uniquement du JSON valide.",
    "temperature": 0.0,
    "max_tokens": 1000
  }

// R√©sultat final: Donn√©es structur√©es de tous les graphiques
```

**Gain**: Pipeline complet d'extraction de donn√©es visuelles sans intervention manuelle

---

### Pattern B: Search (dorking) ‚Üí Research/Quick (exclusive)
**Cas d'usage**: D√©couvrir sources officielles ‚Üí R√©pondre uniquement avec celles-ci

```json
// === √âTAPE 1: D√©couvrir sources officielles ===
POST /api/v1/search
{
  "query": "r√©glementation signalisation routi√®re obligations chantiers",
  "dorking": true,
  "language": "fr",
  "max_results": 10
}

// Le dorking active automatiquement: site:gouv.fr OR site:legifrance.gouv.fr

// R√©sultat:
// {
//   "results": [
//     {"url": "https://legifrance.gouv.fr/codes/id/LEGISCTA000006177118"},
//     {"url": "https://www.securite-routiere.gouv.fr/reglementation-liee-la-route"},
//     {"url": "https://demarches-securite-routes.cerema.fr"}
//   ]
// }

// === √âTAPE 2: R√©ponse avec sources officielles UNIQUEMENT ===
POST /api/v1/research/quick
{
  "query": "Quelles sont les obligations l√©gales de signalisation temporaire sur chantiers routiers?",
  "sources": {
    "urls": [
      "https://legifrance.gouv.fr/codes/id/LEGISCTA000006177118",
      "https://www.securite-routiere.gouv.fr/reglementation-liee-la-route",
      "https://demarches-securite-routes.cerema.fr"
    ],
    "strategy": "exclusive"
  },
  "max_sources": 10,
  "timeout": 120
}

// R√©sultat: R√©ponse 100% bas√©e sur sources officielles
// Z√©ro risque d'informations non v√©rifi√©es
```

**Gain**: Workflow d√©couverte + garantie de fiabilit√©

**Utilisation**:
- Chatbots l√©gaux/r√©glementaires
- Assistants conformit√©
- Documentation officielle

---

### Pattern C: Extract (avec links) ‚Üí Research/Quick (priority)
**Cas d'usage**: Partir d'une page index ‚Üí Extraire tous les liens ‚Üí R√©pondre en privil√©giant la doc

```json
// === √âTAPE 1: Extraire page index + tous les liens ===
POST /api/v1/extract
{
  "url": "https://docs.fastapi.com/tutorial",
  "options": {
    "extract_links": true,
    "extract_images": false
  }
}

// R√©sultat:
// {
//   "links": [
//     {"url": "https://docs.fastapi.com/advanced/security", "text": "Security"},
//     {"url": "https://docs.fastapi.com/deployment", "text": "Deployment"},
//     {"url": "https://docs.fastapi.com/tutorial/database", "text": "Database"}
//   ]
// }

// === √âTAPE 2: Recherche en privil√©giant ces pages ===
POST /api/v1/research/quick
{
  "query": "Comment s√©curiser une API FastAPI avec OAuth2 et JWT?",
  "sources": {
    "urls": [
      "https://docs.fastapi.com/advanced/security",
      "https://docs.fastapi.com/tutorial/security",
      "https://docs.fastapi.com/deployment"
    ],
    "strategy": "priority"
  },
  "max_sources": 8,
  "timeout": 90
}

// Comportement:
// 1. Extrait d'abord la doc officielle (priority)
// 2. Si insuffisant, compl√®te avec recherche web (tutoriels, exemples)
// 3. G√©n√®re r√©ponse qui privil√©gie doc officielle
```

**Gain**: Combine autorit√© de la doc officielle + richesse des exemples communautaires

---

### Pattern D: Search (site targeting) ‚Üí Extract ‚Üí Research/Quick (complement)
**Cas d'usage**: Cibler documentation d'un site ‚Üí Extraire ‚Üí Compl√©ter avec web

```json
// === √âTAPE 1: Rechercher sur site sp√©cifique ===
POST /api/v1/search
{
  "query": "API communes d√©partements endpoints documentation",
  "target_url": "https://geo.api.gouv.fr",
  "scope": "site",
  "max_results": 5
}

// R√©sultat:
// {
//   "results": [
//     {"url": "https://geo.api.gouv.fr/decoupage-administratif/communes"},
//     {"url": "https://geo.api.gouv.fr/decoupage-administratif/departements"}
//   ]
// }

// === √âTAPE 2: Extraire contenu de chaque page doc ===
for each url in results:
  POST /api/v1/extract
  {
    "url": url,
    "options": {"clean_html": true}
  }

// === √âTAPE 3: R√©ponse avec doc site + compl√©ments web ===
POST /api/v1/research/quick
{
  "query": "Comment utiliser l'API Geo pour r√©cup√©rer les communes d'un d√©partement?",
  "sources": {
    "urls": [
      "https://geo.api.gouv.fr/decoupage-administratif/communes",
      "https://geo.api.gouv.fr/decoupage-administratif/departements"
    ],
    "strategy": "complement"
  },
  "max_sources": 10,
  "timeout": 90
}

// Comportement:
// 1. Recherche web normale (exemples, tutoriels)
// 2. Ajoute les pages de doc officielle
// 3. G√©n√®re r√©ponse compl√®te (doc + exemples pratiques)
```

**Gain**: Documentation officielle + exemples de code r√©els

---

### Pattern E: Vision (OCR) ‚Üí Extract ‚Üí Research/Quick
**Cas d'usage**: Screenshot d'une page ‚Üí OCR URL ‚Üí Extraire ‚Üí R√©pondre

```json
// === √âTAPE 1: OCR sur screenshot pour r√©cup√©rer URLs ===
POST /api/v1/vision
{
  "image_url": "https://example.com/screenshot-doc.png",
  "prompt": "Extraire TOUTES les URLs visibles dans cette image. Retourner une liste JSON: [\"url1\", \"url2\", ...]",
  "temperature": 0.0,
  "max_tokens": 500
}

// R√©sultat:
// {
//   "analysis": "[\"https://docs.example.com/api\", \"https://github.com/example/repo\"]"
// }

// === √âTAPE 2: Extraire contenu des URLs ===
for each url in urls:
  POST /api/v1/extract
  {
    "url": url,
    "options": {"clean_html": true}
  }

// === √âTAPE 3: R√©pondre avec contenu extrait ===
POST /api/v1/research/quick
{
  "query": "Comment cette API fonctionne-t-elle? Quels sont les endpoints principaux?",
  "sources": {
    "urls": ["https://docs.example.com/api", "https://github.com/example/repo"],
    "strategy": "exclusive"
  }
}
```

**Gain**: Workflow complet depuis capture d'√©cran (z√©ro copier-coller manuel)

**Utilisation**:
- Agents desktop qui capturent l'√©cran
- Bots Slack/Discord avec screenshots
- Outils de documentation automatique

---

### Pattern F: Search ‚Üí API Navigator ‚Üí Research/Quick
**Cas d'usage**: D√©couvrir API ‚Üí Explorer endpoints ‚Üí R√©pondre avec donn√©es

```json
// === √âTAPE 1: D√©couvrir APIs gouvernementales ===
POST /api/v1/search
{
  "query": "API gouvernementale fran√ßaise communes population",
  "dorking": true,
  "max_results": 3
}

// R√©sultat: https://geo.api.gouv.fr

// === √âTAPE 2: Explorer l'API d√©couverte ===
POST /api/v1/api-navigator
{
  "api_base_url": "https://geo.api.gouv.fr",
  "api_doc_url": "https://geo.api.gouv.fr/decoupage-administratif",
  "user_query": "10 communes fran√ßaises les plus peupl√©es"
}

// R√©sultat:
// {
//   "results": [
//     {"nom": "Paris", "population": 2113705},
//     {"nom": "Marseille", "population": 877215},
//     ...
//   ]
// }

// === √âTAPE 3: R√©pondre avec contexte enrichi ===
POST /api/v1/research/quick
{
  "query": "Quelle est la commune la plus peupl√©e de France et de combien d√©passe-t-elle Marseille?",
  "sources": {
    "urls": ["https://geo.api.gouv.fr/communes"],
    "strategy": "priority"
  }
}
```

**Gain**: D√©couverte automatique d'APIs + exploitation des donn√©es

**Utilisation**:
- Agents de data analysis
- Chatbots avec acc√®s APIs publiques
- Outils d'exploration de donn√©es gouvernementales

---

### Pattern G: Extract (liens + images) ‚Üí Vision (multiple) ‚Üí Research/Quick
**Cas d'usage**: Page complexe ‚Üí Extraire tout ‚Üí Analyser graphiques ‚Üí Synth√®se globale

```json
// === √âTAPE 1: Extraire page compl√®te ===
POST /api/v1/extract
{
  "url": "https://insee.fr/rapport-economique-2024",
  "options": {
    "extract_images": true,
    "extract_links": true
  }
}

// R√©sultat:
// {
//   "content": "Rapport √©conomique 2024...",
//   "images": ["chart1.png", "graph2.png", "table3.png"],
//   "links": ["annexe-1", "annexe-2"]
// }

// === √âTAPE 2: Analyser chaque graphique ===
graph_data = []
for each image in images:
  POST /api/v1/vision
  {
    "image_url": image,
    "prompt": "Extraire toutes les donn√©es num√©riques. Format JSON."
  }
  graph_data.append(response)

// === √âTAPE 3: Synth√®se compl√®te ===
POST /api/v1/research/quick
{
  "query": "Quelles sont les principales tendances √©conomiques 2024 selon ce rapport? Synth√©tiser avec chiffres cl√©s.",
  "sources": {
    "urls": ["https://insee.fr/rapport-economique-2024"],
    "strategy": "exclusive"
  }
}
```

**Gain**: Extraction totale contenu texte + donn√©es visuelles

---

## üéØ Cas d'Usage M√©tier

### 1. Veille R√©glementaire Automatis√©e

**Objectif**: Monitorer changements l√©gislatifs dans un domaine

**Workflow**:
```json
// Quotidien: D√©couverte de nouveaux textes
POST /api/v1/search
{
  "query": "droit du travail france",
  "dorking": true,
  "time_range": "day",
  "max_results": 20
}

// Hebdomadaire: Analyse approfondie des changements
POST /api/v1/research/deep
{
  "topic": "√âvolutions r√©glementaires droit du travail - Semaine du [date]",
  "sources": {
    "domains_whitelist": ["legifrance.gouv.fr", "travail-emploi.gouv.fr"]
  },
  "context": {
    "date_range": "week"
  }
}
```

**Agent recommand√©**: Scheduled job (cron) qui compare rapports semaine N vs N-1

---

### 2. Extraction de Donn√©es Publiques

**Objectif**: R√©cup√©rer datasets gouvernementaux pour analyse

**Workflow**:
```json
// D√©couvrir APIs de donn√©es
POST /api/v1/search
{
  "query": "API donn√©es publiques INSEE population",
  "target_url": "https://api.gouv.fr",
  "scope": "site"
}

// Explorer et r√©cup√©rer donn√©es
POST /api/v1/api-navigator
{
  "api_base_url": "https://api.insee.fr",
  "user_query": "T√©l√©charger donn√©es population par d√©partement"
}
```

**Agent recommand√©**: Pipeline ETL automatis√©

---

### 3. Audit de Conformit√© Documentaire

**Objectif**: V√©rifier qu'un site respecte les r√©glementations

**Workflow**:
```json
// Extraire pages du site √† auditer
POST /api/v1/extract
{
  "url": "https://example.com/mentions-legales",
  "options": {"extract_links": true}
}

// V√©rifier conformit√© avec textes officiels
POST /api/v1/research/quick
{
  "query": "Ce site respecte-t-il les obligations RGPD? Lister les manquements.",
  "sources": {
    "urls": ["https://example.com/mentions-legales", "https://cnil.fr/rgpd"],
    "strategy": "complement"
  }
}
```

---

### 4. G√©n√©ration de Documentation Technique

**Objectif**: Cr√©er doc √† partir de code source + APIs

**Workflow**:
```json
// Analyser structure du projet
POST /api/v1/search
{
  "query": "API endpoints",
  "target_url": "https://github.com/user/project",
  "scope": "site"
}

// G√©n√©rer rapport complet
POST /api/v1/research/deep
{
  "topic": "Documentation compl√®te API [project]",
  "sources": {
    "suggested": ["https://github.com/user/project"]
  },
  "output_format": {
    "structure": "report",
    "sections": ["Architecture", "Endpoints", "Authentication", "Examples"]
  }
}
```

---

### 5. Analyse Concurrentielle

**Objectif**: Comparer produits/services concurrents

**Workflow**:
```json
POST /api/v1/research/deep
{
  "topic": "Analyse concurrentielle - Solutions de [domaine]",
  "objectives": [
    "Identifier les acteurs principaux",
    "Comparer fonctionnalit√©s et prix",
    "Analyser forces et faiblesses",
    "Positionner notre offre"
  ],
  "sources": {
    "exclusions": ["forum.*", "blog.*"]  // √âviter opinions
  },
  "context": {
    "min_sources": 30,
    "include_data": true
  }
}
```

---

## ü§ñ Guide pour D√©veloppeurs d'Agents

### Principes de Design

#### 1. Orchestration Progressive
**Ne pas utiliser deep research si quick suffit**

```python
# ‚ùå Mauvais: Toujours utiliser deep research
response = await client.post("/api/v1/research/deep", json={"topic": query})

# ‚úÖ Bon: Escalade progressive
# 1. Essayer quick d'abord
response = await client.post("/api/v1/research/quick", json={"query": query})

# 2. Si confiance faible ou sources insuffisantes ‚Üí deep
if response["confidence"] == "low" or len(response["sources"]) < 5:
    response = await client.post("/api/v1/research/deep", json={"topic": query})
```

**Gain**: Temps de r√©ponse optimis√© (15s vs 300s)

---

#### 2. Gestion des Timeouts

```python
# Configuration par complexit√© de t√¢che
TIMEOUTS = {
    "extract": 30,
    "vision": 15,
    "search": 30,
    "research_quick": 90,
    "research_deep": 600
}

# Retry avec timeout augment√© si √©chec
async def resilient_request(endpoint, data, max_retries=2):
    timeout = TIMEOUTS[endpoint]
    for attempt in range(max_retries):
        try:
            return await client.post(f"/api/v1/{endpoint}",
                                    json=data,
                                    timeout=timeout)
        except TimeoutError:
            timeout *= 1.5  # Augmenter timeout
            if attempt == max_retries - 1:
                raise
```

---

#### 3. Parall√©lisation des Extractions

```python
# ‚ùå Mauvais: S√©quentiel
for url in urls:
    result = await extract(url)
    results.append(result)

# ‚úÖ Bon: Parall√®le (max 5 concurrent)
import asyncio
from itertools import islice

async def extract_batch(urls, batch_size=5):
    results = []
    for batch in batched(urls, batch_size):
        batch_results = await asyncio.gather(
            *[extract(url) for url in batch],
            return_exceptions=True
        )
        results.extend(batch_results)
    return results
```

---

#### 4. Strat√©gie de Sources Dynamique

```python
def determine_source_strategy(query: str, context: dict) -> dict:
    """
    D√©termine automatiquement la strat√©gie de sources appropri√©e
    """
    # D√©tection de mots-cl√©s l√©gaux/r√©glementaires
    legal_keywords = ["loi", "article", "code", "r√©glementation", "obligation"]
    if any(kw in query.lower() for kw in legal_keywords):
        return {
            "sources": {
                "strategy": "exclusive",
                "urls": discover_official_sources(query)  # D√©couverte pr√©alable
            }
        }

    # D√©tection de documentation technique
    if "documentation" in query.lower() or "doc" in context.get("type", ""):
        return {
            "sources": {
                "strategy": "priority",
                "urls": context.get("doc_urls", [])
            }
        }

    # Par d√©faut: recherche ouverte
    return {"sources": None}

# Usage
config = determine_source_strategy(user_query, context)
response = await client.post("/api/v1/research/quick", json={
    "query": user_query,
    **config
})
```

---

#### 5. Cache Intelligent

```python
from functools import lru_cache
import hashlib

@lru_cache(maxsize=100)
async def cached_extract(url: str):
    """Cache les extractions par URL"""
    return await extract(url)

def cache_key(endpoint: str, params: dict) -> str:
    """G√©n√®re cl√© de cache"""
    return hashlib.md5(
        f"{endpoint}:{json.dumps(params, sort_keys=True)}".encode()
    ).hexdigest()

# Cache Redis pour agents distribu√©s
import aioredis

redis = await aioredis.create_redis_pool('redis://localhost')

async def cached_request(endpoint: str, data: dict, ttl: int = 3600):
    key = cache_key(endpoint, data)

    # V√©rifier cache
    cached = await redis.get(key)
    if cached:
        return json.loads(cached)

    # Requ√™te + mise en cache
    result = await client.post(f"/api/v1/{endpoint}", json=data)
    await redis.setex(key, ttl, json.dumps(result))
    return result
```

---

### Patterns d'Agents Recommand√©s

#### Agent 1: Assistant R√©glementaire
```python
class RegulatoryAssistant:
    """
    Agent sp√©cialis√© dans les questions l√©gales/r√©glementaires
    """

    async def answer(self, query: str) -> dict:
        # 1. D√©couvrir sources officielles
        official_sources = await self.discover_official_sources(query)

        # 2. R√©ponse exclusive sur sources officielles
        response = await client.post("/api/v1/research/quick", json={
            "query": query,
            "sources": {
                "urls": official_sources,
                "strategy": "exclusive"
            },
            "timeout": 120
        })

        # 3. Si √©chec, fallback sur deep research
        if not response["success"]:
            response = await client.post("/api/v1/research/deep", json={
                "topic": query,
                "sources": {
                    "domains_whitelist": ["gouv.fr", "legifrance.gouv.fr"]
                }
            })

        return response

    async def discover_official_sources(self, query: str) -> list:
        """D√©couvre sources officielles via dorking"""
        search_result = await client.post("/api/v1/search", json={
            "query": query,
            "dorking": True,
            "max_results": 10
        })

        # Filtrer uniquement .gouv.fr
        return [
            r["url"] for r in search_result["results"]
            if "gouv.fr" in r["url"]
        ]
```

---

#### Agent 2: Extracteur de Donn√©es Visuelles
```python
class VisualDataExtractor:
    """
    Agent pour extraire donn√©es de graphiques/tableaux
    """

    async def extract_from_url(self, url: str) -> dict:
        # 1. Extraire page + images
        page = await client.post("/api/v1/extract", json={
            "url": url,
            "options": {"extract_images": True}
        })

        # 2. Analyser chaque image
        extracted_data = []
        for img_url in page["images"]:
            vision_result = await client.post("/api/v1/vision", json={
                "image_url": img_url,
                "prompt": "Extraire donn√©es en JSON: {labels: [], values: []}",
                "temperature": 0.0
            })

            try:
                data = json.loads(vision_result["analysis"])
                extracted_data.append({
                    "image": img_url,
                    "data": data
                })
            except json.JSONDecodeError:
                continue

        return {
            "url": url,
            "text": page["content"],
            "visual_data": extracted_data
        }
```

---

#### Agent 3: Veilleur Automatis√©
```python
class AutomatedMonitor:
    """
    Agent de veille qui compare √©tats avant/apr√®s
    """

    def __init__(self, topics: list, check_interval: int = 86400):
        self.topics = topics
        self.check_interval = check_interval  # 24h par d√©faut
        self.previous_state = {}

    async def run(self):
        while True:
            for topic in self.topics:
                # Recherche actuelle
                current = await self.research(topic)

                # Comparaison avec √©tat pr√©c√©dent
                if topic in self.previous_state:
                    changes = self.detect_changes(
                        self.previous_state[topic],
                        current
                    )

                    if changes:
                        await self.notify(topic, changes)

                # MAJ √©tat
                self.previous_state[topic] = current

            await asyncio.sleep(self.check_interval)

    async def research(self, topic: str) -> dict:
        return await client.post("/api/v1/research/deep", json={
            "topic": topic,
            "context": {"date_range": "day"},
            "max_steps": 10,
            "timeout": 300
        })

    def detect_changes(self, old: dict, new: dict) -> list:
        """D√©tecte changements significatifs"""
        changes = []

        # Nouvelles sources
        old_urls = {s["url"] for s in old.get("sources", {}).get("websites", [])}
        new_urls = {s["url"] for s in new.get("sources", {}).get("websites", [])}

        added = new_urls - old_urls
        if added:
            changes.append({"type": "new_sources", "urls": list(added)})

        return changes
```

---

### Best Practices pour Agents

1. **Toujours g√©rer les erreurs**
   - Timeouts
   - Sources indisponibles
   - Formats de r√©ponse inattendus

2. **Impl√©menter fallbacks**
   - Quick ‚Üí Deep si confiance faible
   - Extract ‚Üí Search si URL inaccessible
   - Priority ‚Üí Exclusive si sources critique manquantes

3. **Logger les d√©cisions**
   ```python
   logger.info(f"Strategy: exclusive (detected legal keywords)")
   logger.info(f"Sources discovered: {len(sources)}")
   logger.info(f"Confidence: {response['confidence']}")
   ```

4. **Monitorer les co√ªts**
   - Tracker temps de r√©ponse par endpoint
   - Compter tokens LLM utilis√©s
   - Mesurer cache hit ratio

5. **Tester avec donn√©es r√©elles**
   - Ne pas supposer format de r√©ponse
   - Tester avec timeouts courts
   - Valider avec sources indisponibles

---

## üìä Tableau R√©capitulatif

| Pattern | Endpoints | Param√®tres Cl√©s | Temps | Utilisation |
|---------|-----------|-----------------|-------|-------------|
| **Extraction simple** | 1 | `extract` | 2-30s | Contenu unique |
| **Vision OCR** | 1 | `vision` + `temperature=0` | 1-5s | Documents scann√©s |
| **Search dorking** | 1 | `search` + `dorking=true` | 5-15s | D√©couverte cibl√©e |
| **Quick exclusive** | 1 | `quick` + `strategy=exclusive` | 30-90s | Fiabilit√© 100% |
| **Deep discovery** | 1 | `deep` + `required=[]` | 60-600s | Audit syst√©mique |
| **Deep whitelist** | 1 | `deep` + `domains_whitelist` | 60-600s | Sources officielles |
| **Search‚ÜíExtract‚ÜíVision** | 3 | Cha√Ænage | 30-120s | Donn√©es visuelles |
| **Search‚ÜíQuick** | 2 | D√©couverte + exclusive | 45-120s | Workflow fiable |
| **Extract‚ÜíQuick** | 2 | Links + priority | 30-90s | Doc officielle + web |

---

## üöÄ Pour Aller Plus Loin

- **Documentation API compl√®te**: `/docs` (Swagger UI)
- **Architecture Deep Research**: `DEEP_RESEARCH_ARCHITECTURE.md`
- **Guide des Endpoints**: `ENDPOINTS_GUIDE.md`
- **Exemples Postman**: `examples/webtools-collection.json`

---

**Version**: 1.0.0
**Derni√®re mise √† jour**: 2025-11-19
**Maintenu par**: [@nic01asFr](https://github.com/nic01asFr)
